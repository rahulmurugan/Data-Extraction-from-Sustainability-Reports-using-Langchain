{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "!pip install faiss-cpu\n",
        "!pip install --upgrade openai\n",
        "!pip install PyPDF2\n",
        "!pip install openai\n",
        "#!pip install PyPDF2\n",
        "!pip install langchain\n",
        "!pip install PyPDF2\n",
        "!pip install tabula-py"
      ],
      "metadata": {
        "id": "9Q1HANJrRiUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQm3RTL4RgDx"
      },
      "outputs": [],
      "source": [
        "#NEW CODE with history\n",
        "import os\n",
        "import pickle\n",
        "from PyPDF2 import PdfReader\n",
        "import tabula\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "def setup_openai_api_key():\n",
        "    api_key = input(\"Enter your OpenAI API key: \")\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "      # Use PyPDF2 to extract text from the PDF\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        pdf_reader = PdfReader(pdf_file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_table_info(pdf_path):\n",
        "       # Use tabula-py to extract tables from the PDF\n",
        "    tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)\n",
        "    table_info = []\n",
        "\n",
        "    for table in tables:\n",
        "        # Convert the table data to a list of dictionaries for easier access\n",
        "        table_data = table.to_dict(orient=\"records\")\n",
        "        table_text = \"\\n\".join([\", \".join(str(val) for val in row.values()) for row in table_data])\n",
        "        table_info.append(table_text)\n",
        "\n",
        "    return table_info\n",
        "\n",
        "def main():\n",
        "    # Upload a PDF file\n",
        "    pdf_path = input(\"Enter the path to your PDF file: \")\n",
        "    pdf_name = os.path.basename(pdf_path)\n",
        "\n",
        "    # Extract text from the PDF using PyPDF2\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Preprocess the text to handle any encoding issues or anomalies\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=2000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    text_chunks = text_splitter.split_text(text=text)\n",
        "\n",
        "    # Extract tables from the PDF using tabula-py\n",
        "    table_info = extract_table_info(pdf_path)\n",
        "\n",
        "    # Create vector store for text chunks\n",
        "    text_store_name = pdf_name[:-4] + \"_text\"\n",
        "    if os.path.exists(f\"{text_store_name}.pkl\"):\n",
        "        with open(f\"{text_store_name}.pkl\", \"rb\") as f:\n",
        "            TextVectorStore = pickle.load(f)\n",
        "        print(\"Text embeddings loaded from disk.\")\n",
        "    else:\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        TextVectorStore = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
        "        with open(f\"{text_store_name}.pkl\", \"wb\") as f:\n",
        "            pickle.dump(TextVectorStore, f)\n",
        "        print(\"Text embeddings created and saved to disk.\")\n",
        "\n",
        "    # Create vector store for table data\n",
        "    table_store_name = pdf_name[:-4] + \"_tables\"\n",
        "    if os.path.exists(f\"{table_store_name}.pkl\"):\n",
        "        with open(f\"{table_store_name}.pkl\", \"rb\") as f:\n",
        "            TableVectorStore = pickle.load(f)\n",
        "        print(\"Table embeddings loaded from disk.\")\n",
        "    else:\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        TableVectorStore = FAISS.from_texts(table_info, embedding=embeddings)\n",
        "        with open(f\"{table_store_name}.pkl\", \"wb\") as f:\n",
        "            pickle.dump(TableVectorStore, f)\n",
        "        print(\"Table embeddings created and saved to disk.\")\n",
        "\n",
        "    # Initialize conversation history\n",
        "    conversation = []\n",
        "\n",
        "    # Accept user prompts (questions)\n",
        "    while True:\n",
        "        query = input(\"Ask a question about the PDF file (or type 'exit' to quit): \")\n",
        "        if query.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "        # Append the current query to conversation history\n",
        "        conversation.append(query)\n",
        "\n",
        "        # Customize OpenAI LLM parameters\n",
        "        llm = OpenAI(temperature=0, model_name=\"gpt-4\")\n",
        "\n",
        "        # Combine conversation history with the new query as context\n",
        "        conversation_context = \"\\n\".join(conversation)\n",
        "\n",
        "        # Perform similarity search between query and text chunks\n",
        "        text_docs = TextVectorStore.similarity_search(query=conversation_context, k=3)\n",
        "\n",
        "        # Perform similarity search between query and table data\n",
        "        table_docs = TableVectorStore.similarity_search(query=conversation_context, k=3)\n",
        "\n",
        "        # Combine the results from text and table searches\n",
        "        all_docs = text_docs + table_docs\n",
        "\n",
        "        chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
        "        with get_openai_callback() as cb:\n",
        "            response = chain.run(input_documents=all_docs, question=query)\n",
        "            tokens = cb.total_tokens\n",
        "            cost = cb.total_cost\n",
        "\n",
        "        # Append the response to conversation history\n",
        "        conversation.append(response)\n",
        "\n",
        "        print(\"Cost:\", cost)\n",
        "        print(\"Number of Tokens:\", tokens)\n",
        "        print(response)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    setup_openai_api_key()\n",
        "    main()\n"
      ]
    }
  ]
}